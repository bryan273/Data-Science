# -*- coding: utf-8 -*-
"""Rakamin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rOaAF-N0qFm1tRNYnDaNQENornyAKH4-

Data preparation from google drive
"""

import pandas as pd
import gdown

meta_url = 'https://drive.google.com/uc?export=download&confirm=pbef&id='
link = "1Mx4L0JvFRqboRuB6H7Fp9lO4l-DnJXDU"
url = meta_url + link
output = 'data.csv'
gdown.download(url, output, quiet=True)
data = pd.read_csv(output)

"""Make target from loan status to 1 and 0 -> still loaning and not loaning again"""

data['loan_status'].value_counts()

target = data['loan_status'].str.contains('Charged Off').astype(int)
data['loan_status'] = target

"""Drop the columns that has many missing value"""

data.nunique().sort_values(ascending=False)[:10]

tmp = (data.isnull().sum().sort_values(ascending=False)>20000)
data.drop(tmp[tmp].index, axis=1, inplace=True)

"""Drop columns that has many unique value for categorical"""

data.select_dtypes('object').nunique().sort_values(ascending=False)[:10]

tmp = (data.select_dtypes('object').nunique()>1000)
data.drop(tmp[tmp].index, axis=1, inplace=True)

"""Drop the first three columns because irrevelant"""

data.drop(data.iloc[:,0:3].columns, axis=1, inplace=True)

"""Imputer on the numerical missing value with iterative to learn pattern"""

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

imputer = IterativeImputer()
x = imputer.fit_transform(data.select_dtypes(exclude='object'))

"""Impute the categorical with most frequent value"""

import pandas as pd
import numpy as np

from sklearn.base import TransformerMixin

class DataFrameImputer(TransformerMixin):

    def __init__(self):
        pass
        
    def fit(self, X, y=None):

        self.fill = pd.Series([X[c].value_counts().index[0]
            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],
            index=X.columns)

        return self

    def transform(self, X, y=None):
        return X.fillna(self.fill)

z = DataFrameImputer().fit_transform(data.select_dtypes(include='object'))

pip install catboost --quiet

"""Make the dataframe from numerical and categorical value"""

num = pd.DataFrame(x ,columns = data.select_dtypes(exclude='object').columns)
cat = pd.DataFrame(z ,columns = data.select_dtypes(include='object').columns)

num.drop("loan_status", axis=1, inplace=True)
data.drop("loan_status", axis=1, inplace=True)

"""Standardize the numerical columns"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
num = scaler.fit_transform(num)
num = pd.DataFrame(num ,columns = data.select_dtypes(exclude='object').columns)

data = pd.concat([num, cat], axis=1)

"""Data preview"""

data

"""Split the data"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.15, random_state=42)

col = data.select_dtypes('object').columns.tolist()

"""Train the model with catboost"""

from catboost import CatBoostClassifier

clf = CatBoostClassifier()

clf.fit(
    X_train, y_train,
    cat_features=col,
    eval_set=(X_test, y_test),
    verbose=True,
    plot=True
)

X_test.columns

"""Classification report with catboost
* From the validation set, we can see the model can learn perfectly with the pattern on the data with score = 100%
"""

from sklearn.metrics import classification_report

pred = clf.predict(X_test)
print(classification_report(y_test, pred))

"""Feature importances of the model"""

df = pd.DataFrame({"columns":X_test.columns,"importances":clf.feature_importances_})
df.sort_values(by="importances", ascending=False)